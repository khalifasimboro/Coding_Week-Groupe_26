# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dJaXdfaKCozDW9g8VVh7NY0gjcU0mbfN
"""

"""!pip install xlwt
!pip install imblearn"""

# determiner la donné majoritaire et minoritaire
import pandas as pd
import numpy as np
from sklearn.neighbors import NearestNeighbors
import random
from sklearn.model_selection import train_test_split
from collections import Counter
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import precision_score,accuracy_score, confusion_matrix, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn import tree

arr_data = pd.read_excel("default of credit card clients.xls",header=1,dtype='int8') 
#arr_data = pd.read_excel("/content/default of credit card clients.xls",header=1,dtype='int8')  #en mettant dtype = int32, on réduit la taille de la mémoire, on divise par 8 la taille de la mémoire
arr_data = arr_data.drop(arr_data.columns[0],axis=1)



def compterY(daframe) :  #compte le nombre de majorités et de minorités
  vbin = {}
  dserie = daframe.values[:,-1]
  for i in range(len(dserie)) :
    if f'{dserie[i]}' not in list(vbin.keys()) :
      vbin[f'{dserie[i]}']=1
    else :
      vbin[f'{dserie[i]}'] +=1
  return vbin #les keys sont les valeurs qualitatives et les values sont le nombre de minorité et de majorité

print(compterY(arr_data))

"""On commence à coder  le code SMOTE from scratch. Tout d'abord, on crée une fonction pourcentagequalitatif qui prend en paramètres le dataframe et l'indice de la colonne contenant des valeurs qualitatives. Cette fonction renvoie un dictionnaire dont les valeurs sont les données qualitatives par exemple si on appelle pourcentagequalitatif(arr_dat,1), elle va renvoyer un dictionnaire où les Keys sont 1 (homme) et 2 (femme) et les values sont les proportions d'homme et de femmme"""

def  pourcentagequalitatif(dframe,number):
  col_ = dframe[dframe.columns[number]].tolist()
  liste_ = []
  num_ = {}
  for att in col_ :
    if att not in liste_ :
      liste_.append(att)
      num_[f'{att}']=0

    else :
      num_[f'{att}'] = num_[f'{att}']+1
  liste_clés = list(num_.keys())

  for nombre in range(len(liste_clés)) :
    num_[liste_clés[nombre]] = num_[liste_clés[nombre]] / len(col_)

  #print(num_)
  return num_

#renvoie une liste de valeur de 0 à n-1
def numero(n):
  return [f for f in range(n)]


# Smoteperso Permet d'équilibrer les données du dataframe en paramètre

def SMOTEPERSO(daframe,ntarg,kn):

  dframe = daframe.copy()
  ncol = daframe.shape[1]
  matrice = daframe.values
  num_mino = matrice.shape[0]
  pourcentage_list = [0 for d in range(12)]

  for t in range(1,4) :
    pourcentage_list[t]= pourcentagequalitatif(daframe,t)

  for t in range(5,11) :
    pourcentage_list[t]= pourcentagequalitatif(daframe,t)

  while dframe.shape[0]< ntarg :
    indice = np.random.choice(numero(num_mino))
    x = matrice[indice,:]
    distance = np.tile(x,(num_mino,1)) -  matrice
    distance = np.linalg.norm(distance,axis=1)
    distance=list(enumerate(distance))
    distance.sort(key=lambda x: x[1])
    neighbors = [matrice[v[0],:] for v in distance[1:kn+1]]
    voisin = random.choice(neighbors)
    weight = random.random()
    new_ = np.zeros_like(voisin)
    for m in range(ncol) :
      if m in range(1,4) or m in range(5,11) :
        seuil = random.random()
        prop=pourcentage_list[m]
        list_value= [int(float(d)) for d in list(prop.keys())]
        list_value = list(enumerate(list_value))
        list_value.sort(key=lambda x: x[1])
        donnee = [d[1] for d in list_value]
        prob = [list(prop.values())[d[0]] for d in list_value]
        for k in range(len(donnee)) :
          if  k==0 and seuil <=prob[k] :
            new_[m] = donnee[k]
          elif (k== len(donnee)-1) and 1-prob[k]<=seuil :
            new_[m] = donnee[k]
          elif sum(prob[:k])<=seuil<sum(prob[:k+1]) :
            new_[m] = donnee[k]
      elif m == ncol-1  :
         new_[m] = x[m]
      else :
        new_[m] = int((1-weight)* x[m] + weight*voisin[m])

    new_line = pd.DataFrame([{dframe.columns[j]: new_[j] for j in range(ncol)}])
    dframe = pd.concat([dframe,new_line],ignore_index=True)
    #dframe = dframe.append(new_line,ignore_index=True)
  return dframe

#separation des entrées X et des sorties Y
X = arr_data.drop(arr_data.columns[-1], axis=1)
Y = arr_data[arr_data.columns[-1]]

#separation des données de test et d'entrainement
x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.2, random_state=42)

#Création de dataframe d'entrainement sur lequel on va appliquer notre propre smote
data_train = x_train.copy()
data_train[y_train.name] = y_train.values.tolist()

# Détermination des quantités des données de data_train
compteur = compterY(data_train)
n_min, n_max = min(list(compteur.values())), max(list(compteur.values()))
val_min,val_max = list(compteur.keys())[list(compteur.values()).index(n_min)], list(compteur.keys())[list(compteur.values()).index(n_max)]
print(f'Valeur majoritaire : {val_max}:{n_max}')
print(f'Valeur minoritaire : {val_min}:{n_min}')

#Separation du dataframe en deux dataframe contenant les données minoritaire et majoritaire

Valeur = data_train.values
X = np.zeros((n_max,len(data_train.columns)))
k=0
for i in range(Valeur.shape[0]) :
  if int(Valeur[i,-1])==int(val_max) :
    X[k,:] =  np.array([f for f in Valeur[i,:].tolist()])
    k+=1

Majority_train  = {}
for j in range(len(data_train.columns)):
  Majority_train[f'{data_train.columns[j]}']= X[:,j].tolist()
Majority_train = pd.DataFrame(Majority_train)


X = np.zeros((n_min,len(data_train.columns)))
k=0
for i in range(Valeur.shape[0]) :
  if int(Valeur[i,-1])==int(val_min) :
    X[k,:] =  np.array([f for f in Valeur[i,:].tolist()])
    k+=1

Minority_train  = {}
for j in range(len(data_train.columns)):
  Minority_train[f'{data_train.columns[j]}']= X[:,j].tolist()
Minority_train = pd.DataFrame(Minority_train)

"""Utilisation du smote from scratch sur les données d'entrainements"""

#Equilibrage des données/data balancing

Train_smote= SMOTEPERSO(Minority_train,n_max,3)


mtrain = Majority_train.values
strain = Train_smote.values
ftrain = np.vstack([strain,mtrain])
new_order = np.random.permutation(ftrain.shape[0])
ftrain = ftrain[new_order]
ftrain = pd.DataFrame({f'{arr_data.columns[d]}': ftrain[:,d].tolist() for d in range(ftrain.shape[1])})
my_x,my_y = ftrain.drop(ftrain.columns[-1],axis=1), ftrain[ftrain.columns[-1]]
print(compterY(ftrain))

#Afficher les données équilibrées par smote
ftrain.to_csv("smote.csv",index=False)

"""Utilisation du smote de python sur les données d'entrainements

"""

#algorythme smote

counter = Counter(y_train)
print("Before: ",counter)
#generation données
smt = SMOTE() #k_neighbors

x_train_smote,y_train_smote = smt.fit_resample(x_train,y_train)
counter = Counter(y_train_smote)
print("After: ",counter)

"""Création et évaluation de trois modèle avec Decision tree sur les données pures, données équilibrées avec le smote de python et ceux équilibrées avec le smote crée par l'équipe."""

#Lecture des données
dataframe_classif = arr_data



'''
# Appliquer SMOTE pour rééquilibrer TEST
smote_t = SMOTE(random_state=42, k_neighbors=3)
x_t, y_t=x_test, y_test
x_test, y_test = smote_t.fit_resample(x_t, y_t)
'''

# Instancier votre classe de l'arbre de décision avec les paramètres nécessaires
tree_classif = DecisionTreeClassifier(criterion='entropy', min_samples_split=10,splitter='best', max_depth=3)
tree_classif_smote = DecisionTreeClassifier(criterion='entropy', min_samples_split=10,splitter='best', max_depth=3)
tree_classif_smotefsrc = DecisionTreeClassifier(criterion='entropy', min_samples_split=10,splitter='best', max_depth=3)

# Entraîner le modèle sans smote
tree_trained = tree_classif.fit(x_train, y_train)

# Entraîner le modèle avec smote
tree_trained_smote = tree_classif_smote.fit(x_train_smote, y_train_smote)

# Entraîner le modèle avec le smote from scratch
tree_trained_smotefsrc = tree_classif_smotefsrc.fit(my_x, my_y)

'''
#visualisation de l'arbre
tree.plot_tree(tree_trained)
plt.show()
'''


# Prédire les classes sur l'ensemble de test
y_pred = tree_trained.predict(x_test)
y_pred_smote = tree_trained_smote.predict(x_test)
y_pred_smotefsrc = tree_trained_smotefsrc.predict(x_test)

# Visualisation des poids des variables
print(pd.DataFrame(tree_trained.feature_importances_, index = x_train.columns, columns = ["importance"]).sort_values("importance", ascending = False))

# Calculer et afficher l'exactitude
accuracy = accuracy_score(y_test, y_pred)
accuracy_s = accuracy_score(y_test, y_pred_smote)
accuracy_sf = accuracy_score(y_test, y_pred_smotefsrc)
print("Exactitude:", accuracy)
print("Exactitude smote python:", accuracy_s)
print("Exactitude smote perso:", accuracy_sf)

# Calculer et afficher la précision
precision = precision_score(y_test, y_pred)
precision_s = precision_score(y_test, y_pred_smote)
precision_sf = precision_score(y_test, y_pred_smotefsrc)
print("Précision:", precision)
print("Précision smote python:", precision_s)
print("Précision smote perso:", precision_sf)

# Calculer et afficher le rappel
recall = recall_score(y_test, y_pred)
recall_s = recall_score(y_test, y_pred_smote)
recall_sf = recall_score(y_test, y_pred_smotefsrc)
print("Rappel:", recall)
print("Rappel smote python:", recall_s)
print("Rappel smote perso:", recall_sf)


# Calculer et afficher le score F1
f1 = f1_score(y_test, y_pred)
f1_s = f1_score(y_test, y_pred_smote)
f1_sf = f1_score(y_test, y_pred_smotefsrc)
print("Score F1:", f1)
print("Score F1 smote python :", f1_s)
print("Score F1 smote perso :", f1_sf)

# Calculer et afficher la matrice de confusion
conf_matrix = confusion_matrix(y_test, y_pred)
conf_matrix_s = confusion_matrix(y_test, y_pred_smote)
conf_matrix_sf = confusion_matrix(y_test, y_pred_smotefsrc)
print("Matrice de confusion:")
print(conf_matrix)
print("Matrice de confusion smote python:")
print(conf_matrix_s)
print("Matrice de confusion smote perso:")
print(conf_matrix_sf)

# Calculer et afficher l'aire sous la courbe ROC (AUC)
y_pred_proba = tree_trained.predict_proba(x_test)[:,1]
y_pred_proba_s = tree_trained_smote.predict_proba(x_test)[:,1]
y_pred_proba_sf = tree_trained_smotefsrc.predict_proba(x_test)[:,1]
roc_auc = roc_auc_score(y_test, y_pred_proba)
roc_auc_s = roc_auc_score(y_test, y_pred_proba_s)
roc_auc_sf = roc_auc_score(y_test, y_pred_proba_sf)
print("Aire sous la courbe ROC:", roc_auc)
print("Aire sous la courbe ROC avec smote python:", roc_auc_s)
print("Aire sous la courbe ROC avec smote perso:", roc_auc_sf)

# Tracer la courbe ROC
fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
fpr_s, tpr_s, _ = roc_curve(y_test, y_pred_proba_s)
fpr_sf, tpr_sf, _ = roc_curve(y_test, y_pred_proba_sf)
plt.figure()
plt.plot(fpr, tpr, color='green', lw=2, label='Courbe ROC (AUC = %0.2f)' % roc_auc)
plt.plot(fpr_s, tpr_s, color='red', lw=2,label='Courbe ROC smote python (AUC = %0.2f)' % roc_auc_s)
plt.plot(fpr_sf, tpr_sf, color='blue', lw=2,label='Courbe ROC smote perso (AUC = %0.2f)' % roc_auc_sf)
plt.plot([0, 1], [0, 1], 'r--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taux de faux positifs')
plt.ylabel('Taux de vrais positifs')
plt.title('Courbe ROC')
plt.legend(loc="lower right")
plt.show()

#création de la forèt aleatoire
modele_rf = RandomForestClassifier(
n_estimators=100, #nombre d'arbre dans la foret
criterion='entropy', #critère utilisé pour construire les arbres et séparer les branches des arbres
max_depth=None, #la profondeur maximale des arbres utilisés (le nombre de niveaux dans l’arbre de décision
min_samples_split=2,min_samples_leaf=1,min_weight_fraction_leaf=0.0,max_features='auto',max_leaf_nodes=None,min_impurity_decrease=0.0,
bootstrap=True,oob_score=False,n_jobs=None,random_state=None,verbose=0,warm_start=False,class_weight=None,ccp_alpha=0.0,max_samples=None,)

modele_rfsmtpy = RandomForestClassifier(
n_estimators=100, #nombre d'arbre dans la foret
criterion='entropy', #critère utilisé pour construire les arbres et séparer les branches des arbres
max_depth=None, #la profondeur maximale des arbres utilisés (le nombre de niveaux dans l’arbre de décision
min_samples_split=2,min_samples_leaf=1,min_weight_fraction_leaf=0.0,max_features='auto',max_leaf_nodes=None,min_impurity_decrease=0.0,
bootstrap=True,oob_score=False,n_jobs=None,random_state=None,verbose=0,warm_start=False,class_weight=None,ccp_alpha=0.0,max_samples=None,)

modele_rfsmtscr = RandomForestClassifier(
n_estimators=100, #nombre d'arbre dans la foret
criterion='entropy', #critère utilisé pour construire les arbres et séparer les branches des arbres
max_depth=None, #la profondeur maximale des arbres utilisés (le nombre de niveaux dans l’arbre de décision
min_samples_split=2,min_samples_leaf=1,min_weight_fraction_leaf=0.0,max_features='auto',max_leaf_nodes=None,min_impurity_decrease=0.0,
bootstrap=True,oob_score=False,n_jobs=None,random_state=None,verbose=0,warm_start=False,class_weight=None,ccp_alpha=0.0,max_samples=None,)

#apprentissage du modèle
rf_classifier=modele_rf.fit(x_train, y_train)
rf_classifierpy=modele_rfsmtpy.fit(x_train_smote, y_train_smote)
rf_classifierscr=modele_rfsmtscr.fit(my_x, my_y)

# Faire des prédictions sur l'ensemble de test
y_pred = rf_classifier.predict(x_test)
y_predpy = rf_classifierpy.predict(x_test)
y_predscr = rf_classifierscr.predict(x_test)

#visualisation du pourcentage de bien classés ou accuracy
print(f"Le pourcentage de bien classés est de xtrain : {accuracy_score(y_test, y_pred)*100} %")
print(f"Le pourcentage de bien classés est de xtrain SMOTE Python : {accuracy_score(y_test, y_predpy)*100} %")
print(f"Le pourcentage de bien classés est de xtrain SMOTE from scratch : {accuracy_score(y_test, y_predscr)*100} %")



# Calculer la précision
print("Précision :", precision_score(y_test, y_pred))
print("Précision SMOTE PYTHON :", precision_score(y_test, y_predpy))
print("Précision SMOTE from scratch :", precision_score(y_test, y_predscr))

# Calculer le rappel
print("Rappel :", recall_score(y_test, y_pred))
print("Rappel SMOTE PYTHON:", recall_score(y_test, y_predpy))
print("Rappel SMOTE from scartch:", recall_score(y_test, y_predscr))

# Calculer le F1-score (ou P1_score)
print("F1-score (P1_score) :", f1_score(y_test, y_pred))
print("F1-score (P1_score) SMOTE PYTHON :", f1_score(y_test, y_predpy))
print("F1-score (P1_score) SMOTE from scartch :", f1_score(y_test, y_predscr))

#matrice de confusion
confus_matrix = confusion_matrix(y_test, y_pred)
confus_matrixpy = confusion_matrix(y_test, y_predpy)
confus_matrixscr = confusion_matrix(y_test, y_predscr)
print("Matrice de confusion :")
print(confus_matrix)
print("Matrice de confusion smote python:")
print(confus_matrixpy)
print("Matrice de confusion smote from scratch:")
print(confus_matrixscr)


# Calculer la courbe ROC
fpr, tpr, thresholds = roc_curve(y_test, y_pred)
fpr_py, tpr_py, thresholds_py = roc_curve(y_test, y_predpy)
fpr_scr, tpr_scr, thresholds_scr = roc_curve(y_test, y_predscr)

# Calculer l'aire sous la courbe ROC (AUC)
auc= roc_auc_score(y_test, y_pred)
auc_py = roc_auc_score(y_test, y_predpy)
auc_scr = roc_auc_score(y_test, y_predscr)
print("l'air sous la courbe vaut:",auc)
print("l'air sous la courbe vaut avec SMOTE PYTHON :",auc_py)
print("l'air sous la courbe vaut avec SMOTE from scartch :",auc_scr)

# Tracer la courbe ROC
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % auc)
plt.plot(fpr_py, tpr_py, color='red', lw=2, label='ROC curve SMOTE PYTHON (AUC = %0.2f)' % auc_py)
plt.plot(fpr_scr, tpr_scr, color='green', lw=2, label='ROC curve SMOTE from scratch (AUC = %0.2f)' % auc_scr)
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taux de faux positifs (FPR)')
plt.ylabel('Taux de vrais positifs (TPR)')
plt.title('Courbe ROC')
plt.legend(loc="lower right")
plt.show()

"""BONUS

"""

def memory(dframe) :
  memo = dframe.memory_usage(deep=True,index=False)
  memo = memo.values
  top = list(enumerate(memo.tolist()))
  top.sort(key=lambda x: x[1])
  top_columns = [d[1] for d in top]
  return top_columns